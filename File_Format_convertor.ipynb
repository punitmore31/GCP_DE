{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e15019",
   "metadata": {},
   "source": [
    "The glob module in Python is used to find all pathnames matching a specified pattern according to the rules used by the Unix shell. It's a powerful tool for finding files and directories on your filesystem using wildcards. ðŸ“‚\n",
    "\n",
    "## How It Works: Wildcard Patterns\n",
    "glob works by using special characters, called wildcards, to create a search pattern. The most common wildcards are:\n",
    "\n",
    "Wildcard\tDescription\tExample\n",
    "*\tMatches zero or more characters.\t*.csv matches data.csv and sales.csv.\n",
    "?\tMatches exactly one character.\tphoto_?.jpg matches photo_1.jpg but not photo_10.jpg.\n",
    "[]\tMatches a single character from a set.\treport_[123].txt matches report_1.txt or report_2.txt.\n",
    "**\tMatches all files and zero or more directories and subdirectories.\t**/*.csv finds all CSV files in the current directory and all subdirectories.\n",
    "\n",
    "Export to Sheets\n",
    "## Practical Examples\n",
    "To use glob, you first need to import it. Let's assume you have the following directory structure:\n",
    "\n",
    "/my_project/\n",
    "â”œâ”€â”€ data.csv\n",
    "â”œâ”€â”€ notes.txt\n",
    "â”œâ”€â”€ report.txt\n",
    "â””â”€â”€ /archive/\n",
    "    â”œâ”€â”€ old_notes.txt\n",
    "    â””â”€â”€ backup.zip\n",
    "1. Finding All .txt Files in the Current Directory\n",
    "The glob.glob() function returns a list of matching file paths.\n",
    "\n",
    "Python\n",
    "\n",
    "import glob\n",
    "\n",
    "# Assuming the current working directory is /my_project/\n",
    "txt_files = glob.glob('*.txt')\n",
    "print(txt_files)\n",
    "Output:\n",
    "\n",
    "['notes.txt', 'report.txt']\n",
    "2. Recursive Search with **\n",
    "To search in all subdirectories, use the ** wildcard and set the recursive=True flag.\n",
    "\n",
    "Python\n",
    "\n",
    "import glob\n",
    "\n",
    "# Assuming the current working directory is /my_project/\n",
    "all_txt_files = glob.glob('**/*.txt', recursive=True)\n",
    "print(all_txt_files)\n",
    "Output:\n",
    "\n",
    "['notes.txt', 'report.txt', 'archive/old_notes.txt']\n",
    "ðŸ‘‰ Notice how it found the text file inside the archive folder.\n",
    "\n",
    "## Key Functions: glob vs. iglob\n",
    "The glob module has two primary functions:\n",
    "\n",
    "glob.glob(): Returns a list containing all the matching pathnames. This is easy to use but can consume a lot of memory if you are matching a very large number of files.\n",
    "\n",
    "glob.iglob(): Returns an iterator instead of a list. This is much more memory-efficient because it yields one pathname at a time in a for loop, rather than loading them all into memory at once. You should prefer iglob when you expect a large number of results.\n",
    "\n",
    "Python\n",
    "\n",
    "import glob\n",
    "\n",
    "# Using iglob is more memory-efficient for many files\n",
    "for filename in glob.iglob('**/*.txt', recursive=True):\n",
    "    print(f\"Found file: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cf3daba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d3370f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found file: DE.ipynb\n",
      "Found file: File_Format_convertor.ipynb\n",
      "Found file: pyprog.ipynb\n"
     ]
    }
   ],
   "source": [
    "for i in glob.iglob('*.ipynb'):\n",
    "    print(f\"Found file: {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2106e230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['retail_db\\\\',\n",
       " 'retail_db\\\\categories',\n",
       " 'retail_db\\\\categories\\\\categories.txt',\n",
       " 'retail_db\\\\customers',\n",
       " 'retail_db\\\\customers\\\\customers.txt',\n",
       " 'retail_db\\\\departments',\n",
       " 'retail_db\\\\departments\\\\departments.txt',\n",
       " 'retail_db\\\\departments\\\\test1.csv',\n",
       " 'retail_db\\\\departments\\\\test2.csv',\n",
       " 'retail_db\\\\orders',\n",
       " 'retail_db\\\\orders\\\\orders.txt',\n",
       " 'retail_db\\\\order_items',\n",
       " 'retail_db\\\\order_items\\\\order_items.txt',\n",
       " 'retail_db\\\\products',\n",
       " 'retail_db\\\\products\\\\products.txt',\n",
       " 'retail_db\\\\schemas.json',\n",
       " 'retail_db\\\\simple.json']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('retail_db/**', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a7f97ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['retail_db\\\\categories\\\\categories.txt',\n",
       " 'retail_db\\\\customers\\\\customers.txt',\n",
       " 'retail_db\\\\departments\\\\departments.txt',\n",
       " 'retail_db\\\\orders\\\\orders.txt',\n",
       " 'retail_db\\\\order_items\\\\order_items.txt',\n",
       " 'retail_db\\\\products\\\\products.txt']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_file_name = glob.glob('retail_db/*/*.txt',recursive=True)\n",
    "src_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c328d329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6b6ab441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', 'bar', 'baz', 'qux']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'[\\s,;]+', 'foo,bar;baz  qux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8781c8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['retail_db\\\\categories\\\\categories.txt']\n",
      "['retail_db\\\\customers\\\\customers.txt']\n",
      "['retail_db\\\\departments\\\\departments.txt']\n",
      "['retail_db\\\\orders\\\\orders.txt']\n",
      "['retail_db\\\\order_items\\\\order_items.txt']\n",
      "['retail_db\\\\products\\\\products.txt']\n"
     ]
    }
   ],
   "source": [
    "for file in src_file_name:\n",
    "    file_path_list = re.split(r'[\\s,;]+', file)\n",
    "    print(file_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "198d2311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- ['retail_db\\\\products\\\\products.txt'] --------------------\n",
      "['retail_db\\\\categories\\\\categories.txt',\n",
      " 'retail_db\\\\customers\\\\customers.txt',\n",
      " 'retail_db\\\\departments\\\\departments.txt',\n",
      " 'retail_db\\\\orders\\\\orders.txt',\n",
      " 'retail_db\\\\order_items\\\\order_items.txt',\n",
      " 'retail_db\\\\products\\\\products.txt']\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import  shutil\n",
    "print('-----------------',file_path_list, \"--------------------\")\n",
    "pp.pprint(src_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "510545ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retail_db\\categories\\categories.txt :\n",
      "Shape of  retail_db\\categories\\categories.txt is (58, 3)\n",
      "retail_db\\customers\\customers.txt :\n",
      "Shape of  retail_db\\customers\\customers.txt is (12435, 9)\n",
      "retail_db\\departments\\departments.txt :\n",
      "Shape of  retail_db\\departments\\departments.txt is (6, 2)\n",
      "retail_db\\orders\\orders.txt :\n",
      "Shape of  retail_db\\orders\\orders.txt is (68883, 4)\n",
      "retail_db\\order_items\\order_items.txt :\n",
      "Shape of  retail_db\\order_items\\order_items.txt is (172198, 6)\n",
      "retail_db\\products\\products.txt :\n",
      "Shape of  retail_db\\products\\products.txt is (1345, 6)\n"
     ]
    }
   ],
   "source": [
    "for file in src_file_name:\n",
    "    print(file,':')\n",
    "    df = pd.read_csv(file, header=None)\n",
    "    print(f'Shape of  {file} is {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "adb2e81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'categories': [{'column_name': 'category_id',\n",
      "                 'column_position': 1,\n",
      "                 'data_type': 'integer'},\n",
      "                {'column_name': 'category_department_id',\n",
      "                 'column_position': 2,\n",
      "                 'data_type': 'integer'},\n",
      "                {'column_name': 'category_name',\n",
      "                 'column_position': 3,\n",
      "                 'data_type': 'string'}],\n",
      " 'customers': [{'column_name': 'customer_id',\n",
      "                'column_position': 1,\n",
      "                'data_type': 'integer'},\n",
      "               {'column_name': 'customer_fname',\n",
      "                'column_position': 2,\n",
      "                'data_type': 'string'},\n",
      "               {'column_name': 'customer_lname',\n",
      "                'column_position': 3,\n",
      "                'data_type': 'string'},\n",
      "               {'column_name': 'customer_email',\n",
      "                'column_position': 4,\n",
      "                'data_type': 'string'},\n",
      "               {'column_name': 'customer_password',\n",
      "                'column_position': 5,\n",
      "                'data_type': 'string'},\n",
      "               {'column_name': 'customer_street',\n",
      "                'column_position': 6,\n",
      "                'data_type': 'string'},\n",
      "               {'column_name': 'customer_city',\n",
      "                'column_position': 7,\n",
      "                'data_type': 'string'},\n",
      "               {'column_name': 'customer_state',\n",
      "                'column_position': 8,\n",
      "                'data_type': 'string'},\n",
      "               {'column_name': 'customer_zipcode',\n",
      "                'column_position': 9,\n",
      "                'data_type': 'integer'}],\n",
      " 'departments': [{'column_name': 'department_id',\n",
      "                  'column_position': 1,\n",
      "                  'data_type': 'integer'},\n",
      "                 {'column_name': 'department_name',\n",
      "                  'column_position': 2,\n",
      "                  'data_type': 'string'}],\n",
      " 'order_items': [{'column_name': 'order_item_id',\n",
      "                  'column_position': 1,\n",
      "                  'data_type': 'integer'},\n",
      "                 {'column_name': 'order_item_order_id',\n",
      "                  'column_position': 2,\n",
      "                  'data_type': 'integer'},\n",
      "                 {'column_name': 'order_item_product_id',\n",
      "                  'column_position': 3,\n",
      "                  'data_type': 'integer'},\n",
      "                 {'column_name': 'order_item_quantity',\n",
      "                  'column_position': 4,\n",
      "                  'data_type': 'integer'},\n",
      "                 {'column_name': 'order_item_subtotal',\n",
      "                  'column_position': 5,\n",
      "                  'data_type': 'float'},\n",
      "                 {'column_name': 'order_item_product_price',\n",
      "                  'column_position': 6,\n",
      "                  'data_type': 'float'}],\n",
      " 'orders': [{'column_name': 'order_id',\n",
      "             'column_position': 1,\n",
      "             'data_type': 'integer'},\n",
      "            {'column_name': 'order_date',\n",
      "             'column_position': 2,\n",
      "             'data_type': 'string'},\n",
      "            {'column_name': 'customer_id',\n",
      "             'column_position': 3,\n",
      "             'data_type': 'timestamp'},\n",
      "            {'column_name': 'order_status',\n",
      "             'column_position': 4,\n",
      "             'data_type': 'string'}],\n",
      " 'products': [{'column_name': 'product_id',\n",
      "               'column_position': 1,\n",
      "               'data_type': 'integer'},\n",
      "              {'column_name': 'product_cateogry_id',\n",
      "               'column_position': 2,\n",
      "               'data_type': 'integer'},\n",
      "              {'column_name': 'product_name',\n",
      "               'column_position': 3,\n",
      "               'data_type': ''},\n",
      "              {'column_name': 'product_description',\n",
      "               'column_position': 4,\n",
      "               'data_type': 'string'},\n",
      "              {'column_name': 'product_price',\n",
      "               'column_position': 5,\n",
      "               'data_type': 'float'},\n",
      "              {'column_name': 'product_image',\n",
      "               'column_position': 6,\n",
      "               'data_type': 'string'}]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "json_schema = json.load(open('retail_db/schemas.json', 'r'))\n",
    "pp.pprint(json_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0f74c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_name(schemas,db_name, Sorting_key = 'column_position'):\n",
    "    key = schemas.get(db_name)\n",
    "    columns_list = sorted(key, key=lambda x: x[Sorting_key])\n",
    "    #pp.pprint(columns_list)\n",
    "    column_name = [col['column_name'] for col in columns_list]\n",
    "    return column_name\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f03d1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['category_id', 'category_department_id', 'category_name']\n",
      "['department_id', 'department_name']\n"
     ]
    }
   ],
   "source": [
    "#order_col_name = get_column_name(json_schema, 'orders')\n",
    "category_col_name = get_column_name(json_schema, 'categories')\n",
    "print(category_col_name)\n",
    "department_col_name = get_column_name(json_schema, 'departments')\n",
    "print(department_col_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "da50ac1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************\n",
      "   category_id  category_department_id        category_name\n",
      "0            1                       2             Football\n",
      "1            2                       2               Soccer\n",
      "2            3                       2  Baseball & Softball\n",
      "3            4                       2           Basketball\n",
      "4            5                       2             Lacrosse\n",
      "\n",
      "****************************************************************\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "categories = pd.read_csv(r\"C:\\Users\\punitkumar.more\\Documents\\Elisa\\gcp_de\\GCP_DE\\AUTOMATION\\retail_db\\categories\\categories.txt\",names=category_col_name)\n",
    "print('***************************************************************')\n",
    "print(categories.head(),end='\\n\\n')\n",
    "print('****************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8bc711a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['retail_db', 'categories', 'categories.txt']\n",
      "['retail_db', 'customers', 'customers.txt']\n",
      "['retail_db', 'departments', 'departments.txt']\n",
      "['retail_db', 'orders', 'orders.txt']\n",
      "['retail_db', 'order_items', 'order_items.txt']\n",
      "['retail_db', 'products', 'products.txt']\n"
     ]
    }
   ],
   "source": [
    "for  file in src_file_name:\n",
    "    file_path_list = re.split(r'[\\\\]+', file)\n",
    "    print(file_path_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fe2736de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'retail_db\\\\categories\\\\categories.txt'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = src_file_name[0]\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "b83b66c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\punitkumar.more\\\\Documents\\\\Elisa\\\\gcp_de\\\\GCP_DE\\\\AUTOMATION\\\\retail_db_json/categories', 'C:\\\\Users\\\\punitkumar.more\\\\Documents\\\\Elisa\\\\gcp_de\\\\GCP_DE\\\\AUTOMATION\\\\retail_db_json/customers', 'C:\\\\Users\\\\punitkumar.more\\\\Documents\\\\Elisa\\\\gcp_de\\\\GCP_DE\\\\AUTOMATION\\\\retail_db_json/departments', 'C:\\\\Users\\\\punitkumar.more\\\\Documents\\\\Elisa\\\\gcp_de\\\\GCP_DE\\\\AUTOMATION\\\\retail_db_json/orders', 'C:\\\\Users\\\\punitkumar.more\\\\Documents\\\\Elisa\\\\gcp_de\\\\GCP_DE\\\\AUTOMATION\\\\retail_db_json/order_items', 'C:\\\\Users\\\\punitkumar.more\\\\Documents\\\\Elisa\\\\gcp_de\\\\GCP_DE\\\\AUTOMATION\\\\retail_db_json/products']\n"
     ]
    }
   ],
   "source": [
    "json_file_path = r'C:\\Users\\punitkumar.more\\Documents\\Elisa\\gcp_de\\GCP_DE\\AUTOMATION\\retail_db_json'\n",
    "json_full_file_path = []\n",
    "for file in src_file_name:\n",
    "    file_name = re.split(r'[\\\\]',file)\n",
    "    # print(file_name)\n",
    "    file_folder_name = file_name[-2]\n",
    "    # print(file_folder_name)\n",
    "    json_full_file_path.append(f'{json_file_path}/{file_folder_name}')\n",
    "\n",
    "print(json_full_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5340074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating the path\n",
      "path created successfully C:\\Users\\punitkumar.more\\Documents\\Elisa\\gcp_de\\GCP_DE\\AUTOMATION\\retail_db_json/categories\n",
      "creating the path\n",
      "path created successfully C:\\Users\\punitkumar.more\\Documents\\Elisa\\gcp_de\\GCP_DE\\AUTOMATION\\retail_db_json/customers\n",
      "creating the path\n",
      "path created successfully C:\\Users\\punitkumar.more\\Documents\\Elisa\\gcp_de\\GCP_DE\\AUTOMATION\\retail_db_json/departments\n",
      "creating the path\n",
      "path created successfully C:\\Users\\punitkumar.more\\Documents\\Elisa\\gcp_de\\GCP_DE\\AUTOMATION\\retail_db_json/orders\n",
      "creating the path\n",
      "path created successfully C:\\Users\\punitkumar.more\\Documents\\Elisa\\gcp_de\\GCP_DE\\AUTOMATION\\retail_db_json/order_items\n",
      "creating the path\n",
      "path created successfully C:\\Users\\punitkumar.more\\Documents\\Elisa\\gcp_de\\GCP_DE\\AUTOMATION\\retail_db_json/products\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for f in json_full_file_path:\n",
    "    if os.path.exists(f):\n",
    "        print(f'path aleady exist {f}')\n",
    "    else : \n",
    "        print(\"creating the path\")\n",
    "        try : \n",
    "            os.makedirs(f,exist_ok=True)\n",
    "            print(f'path created successfully {f}')\n",
    "        except : \n",
    "            print(f\"Error in path creation {f}\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc8ee4d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5cbd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import pprint as pp\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9e90ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\punitkumar.more\\\\Documents\\\\Elisa\\\\gcp_de\\\\GCP_DE\\\\AUTOMATION\\\\db_schemas.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpprint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mglob\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m schemas = json.load(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mUsers\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mpunitkumar.more\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDocuments\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mElisa\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mgcp_de\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mGCP_DE\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mAUTOMATION\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mdb_schemas.json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m      7\u001b[39m retail_db_json = \u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mpunitkumar.more\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDocuments\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mElisa\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mgcp_de\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mGCP_DE\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mAUTOMATION\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mretail_db_json\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# pp.pprint(schemas)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\punitkumar.more\\Documents\\Elisa\\gcp_de\\AUTOMATION\\myenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\punitkumar.more\\\\Documents\\\\Elisa\\\\gcp_de\\\\GCP_DE\\\\AUTOMATION\\\\db_schemas.json'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import pprint as pp\n",
    "import glob\n",
    "schemas = json.load(open(r'C:\\Users\\punitkumar.more\\Documents\\Elisa\\gcp_de\\GCP_DE\\AUTOMATION\\db_schemas.json','r'))\n",
    "retail_db_json = r'C:\\Users\\punitkumar.more\\Documents\\Elisa\\gcp_de\\GCP_DE\\AUTOMATION\\retail_db_json'\n",
    "# pp.pprint(schemas)\n",
    "file_path_list = []\n",
    "for i in glob.iglob('retail_db/*/*.txt', recursive=True):\n",
    "    file_path_list.append(i)\n",
    "file_path_list.sort()\n",
    "print(f'Extracted the File path : ')\n",
    "pp.pprint(file_path_list)\n",
    "print(\"****\"*25)\n",
    "\n",
    "def get_column_name(schemas,*db_name_list, sorting_key = 'column_position'):\n",
    "    for i,file in enumerate(file_path_list):\n",
    "        db_name = db_name_list[i]\n",
    "        print(f'DB_NAME : ',db_name)\n",
    "        column_name_list = schemas.get(db_name)\n",
    "        print(f'Columns name list of {db_name} : ')\n",
    "        print(column_name_list)\n",
    "        column_names = [col['column_name'] for col in sorted(column_name_list, key= lambda x : x[sorting_key], reverse=False)]\n",
    "        print(f'{db_name} Column name : ',column_names)\n",
    "        print('----------'*25)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(file, names=column_names)\n",
    "            base_file_name = os.path.splitext(os.path.basename(file))[0]\n",
    "        except :\n",
    "            print(\"no such file\")\n",
    "        print(f'base_file_name: {base_file_name}')\n",
    "        retail_db_json_full_path = os.path.join(retail_db_json,db_name,f'{base_file_name}.json')\n",
    "        retail_db_json_path = os.path.join(retail_db_json,db_name)\n",
    "        print(f'retail_db_json_full_path : {retail_db_json_full_path}')\n",
    "        if os.path.exists(retail_db_json_path):\n",
    "            print(f\"loading json for {db_name}\")\n",
    "            df.to_json(retail_db_json_full_path, orient='records', lines=True)\n",
    "        else :\n",
    "            os.makedirs(retail_db_json_path, exist_ok=True)\n",
    "            df.to_json(retail_db_json_full_path,orient='records',lines=True)\n",
    "\n",
    "\n",
    "db_name_list = [i for i in schemas.keys()]\n",
    "db_name_list.sort()\n",
    "print(f\"Extracted the table name from JSON : \")\n",
    "pp.pprint(db_name_list)\n",
    "print('****'*25)\n",
    "\n",
    "get_column_name(schemas, *db_name_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac4872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
